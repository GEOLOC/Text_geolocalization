{"name":"GEOLOC","tagline":"Geolocalization, text mining, georeference","body":"#Geolocate package for any text\r\n\r\nThis package can be used on any text that has a word that can be geolocated,for instance the name of a city, a town, an important monument or place.\r\n\r\nThe first purpose of this package is geolocalize news that previously have not been tagged on any place. In a first step the script identifies all the words that begin with capital letters. For instances, proper personal names \"Carlos, Laia, Joan\", as well as places: \"Barcelona, New York, Notre Dam, Eiffel Tower , etc\". The script creates a python dictionary of all the capitalizes word and in this list of word, the script checks if the word can be geolocated.\r\n\r\nIf you are a news agency that has a huge database of news, but that has never been geolocalized all your information, this software is designed for you; if you are a journalist that has to cover any report but are not sure where are exactly the places that you must include in your text, the software automatically geolocates all the places that you include in the document. In a similar way if you are a professor  that wants to teach a little bit of geography to your students, this can be a good tool that helps them also to practice their writing. There are multiple uses, maybe more than we can imagine. \r\n\r\n##How the script geolocalized.\r\n\r\n![](https://cloud.githubusercontent.com/assets/7750268/8619618/bab088c2-2718-11e5-87a4-11839a043acb.PNG)\r\n\r\n\r\nThe software uses the wikipedia API *(Application Programming Interface)* in a first stage. Each time it comes across a new word (or a compound expression) that begins with a capital letter, our program connects with Wikipedia and checks if the word page has coordinates. If it doesn’t, or there is no article for this word, the word is saved in our dictionary with a 0. On the other hand, if the Wikipedia api  positively responds to our coordinate request, we store both the coordinates and the word.\r\nTherefore, if we happen to encounter again one of these words, we will not need to ask Wikipedia again and our program will run much faster.\r\n\r\n###Why wikipedia and not a more traditional geolocation service? (Ex: Open maps, Google maps, Geocodes, etc...)\r\n\r\nOne of the first challenges when developing the aforementioned script was to chose  a good source of geolocation places. First, we thought of loading a static database like The Cartography Catalan Service. However, it only has town and city names, which is not enough for our purposes. Other sources of information, like Geonames and Google maps, are fetched with too much un-hierarchized information. \r\nThe local Wikipedia, in our case the catalan version, provides us with the necessary positive bias needed to accomplish our task, as it gives more weight to those entities that are more relevant to the local targeted community.\r\nAlso Wikipedia give us the chance to develop a personalize tools for almost any language. In this first beta version the corpus of news (text) is in catalan, but we can adapt relatively easy the package to work on any language. \r\nAlso , the Wikipedia API give us the chance to create contents of \"augmented reality\", we do not limit to the content of the corpus under analysis , we can improved and mix with new information.  \r\n\r\n##Some Examples\r\n \r\n![](https://cloud.githubusercontent.com/assets/7750268/8593697/4e1f3e08-263a-11e5-97ee-491c7b02e933.png)\r\n\r\nThe figure above is an example of a heat map day by day of the news activity during 2014.\r\n\r\n![](https://cloud.githubusercontent.com/assets/7750268/8593743/c2abf31a-263a-11e5-84f3-5227f8ccd616.png)\r\n\r\nIn the previous figure we can also observe a head map, but we modify the period of change (three days of differences) to perceive better  dynamic of the news saliency on different places. \r\n\r\n![](https://cloud.githubusercontent.com/assets/7750268/8593797/3b777e2c-263b-11e5-8f37-5427c78a8081.png)\r\n\r\nFinally, in the figure above we show the set of news on the territory , when you select a node immediately you see the code of the different news that are associated with that place. \r\n\r\nThe interactive figures are published in this link, where you can find a more detail explanation of this script and the results[http://geolocnews.tumblr.com/Geoloc](http://geolocnews.tumblr.com/Geoloc)\r\n\r\n##README *(How to run this script)* \r\nThis script is in python (v.2.7) to run it you need the following packages: \r\n* pip install wikipedia\r\n* pip install re\r\n* pip install json\r\n* pip install panda \r\n\r\n## Authors (alphabetic order) \r\nRoderic Guigo, Jorge L Salcedo, Adrià San José, Manel Vila, Josep Zapata. \r\n\r\n### Support or Contact\r\nHaving trouble with Pages? Check out our [documentation](https://help.github.com/pages) or [contact support](https://github.com/contact) and we’ll help you sort it out.","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}